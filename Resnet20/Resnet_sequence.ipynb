{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Input\n",
    "from tensorflow.keras.layers import Flatten, add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter\n",
    "\n",
    "batch_size = 32 #실제 논문에서는 128\n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "num_class = 10\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtract_pixel_mean = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 1\n",
    "#ResNet v1 = 1\n",
    "#ResNet v2 = 2\n",
    "\n",
    "if version ==1:\n",
    "    depth = n*6+2\n",
    "elif version == 2:\n",
    "    depth = n*9+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'ResNet%dv%d' % (depth,version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train,axis = 0)\n",
    "    x_train -=x_train_mean\n",
    "    x_test -= x_train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_class)\n",
    "y_test = to_categorical(y_test, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    \n",
    "    if epoch > 180:\n",
    "        lr *=0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *=1e-3\n",
    "    elif epoch >120:\n",
    "        lr *=1e-2\n",
    "    elif epoch >80:\n",
    "        lr *= 1e-1\n",
    "        \n",
    "    print(lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_RESNET(inputs,\n",
    "                num_filter = 16,\n",
    "                kernel_size = 3,\n",
    "                strides = 1,\n",
    "                activation = 'relu',\n",
    "                batch_normalization = True,\n",
    "                conv_first = True):\n",
    "    \n",
    "    conv = Conv2D(num_filter,\n",
    "                 kernel_size = kernel_size,\n",
    "                 strides = strides,\n",
    "                 padding = \"same\",\n",
    "                 kernel_initializer = 'he_normal',\n",
    "                 kernel_regularizer = l2(1e-4))\n",
    "    \n",
    "    x = inputs\n",
    "    \n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation != None:\n",
    "            x = Activation(activation)(x)\n",
    "        \n",
    "    else :\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation != None:\n",
    "            x = Activation(activation)(x)\n",
    "        \n",
    "        x = conv(x)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnetv1(input_shape , depth, num_class = 10,layer_num=3):\n",
    "    \n",
    "    if (depth-2)%6 !=0 :\n",
    "        raise ValueError('depth should be 6n+2 current Depth : '+depth)\n",
    "        \n",
    "    num_fitler = 16\n",
    "    num_res_block = int((depth-2)/6)\n",
    "    \n",
    "    inputs = Input(shape = input_shape)\n",
    "    \n",
    "    x = layer_RESNET(inputs = inputs)\n",
    "    \n",
    "    for stack in range(layer_num):\n",
    "        \n",
    "        for res_block in range(num_res_block):\n",
    "            \n",
    "            stride = 1\n",
    "            \n",
    "            if stack >0 and res_block == 0:\n",
    "                stride = 2\n",
    "            \n",
    "            y = layer_RESNET(\n",
    "                inputs = x,\n",
    "                num_filter = num_fitler,\n",
    "                strides = stride\n",
    "            )\n",
    "            y = layer_RESNET(\n",
    "                inputs = y,\n",
    "                num_filter = num_fitler,\n",
    "                activation = None\n",
    "            )\n",
    "            \n",
    "            if stack>0 and res_block ==0 :\n",
    "                x = layer_RESNET(\n",
    "                    inputs = x,\n",
    "                    num_filter= num_fitler,\n",
    "                    kernel_size = 1,\n",
    "                    strides= stride,\n",
    "                    activation = None,\n",
    "                    batch_normalization = False\n",
    "                )\n",
    "                \n",
    "            x = add([x,y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_fitler *=2\n",
    "        \n",
    "    x = AveragePooling2D(pool_size = 8 )(x)\n",
    "    y = Flatten()(x)\n",
    "    \n",
    "    outputs = Dense(\n",
    "        num_class,\n",
    "        activation = 'softmax',\n",
    "        kernel_initializer = 'he_normal'\n",
    "                   )(y)\n",
    "    \n",
    "    model = Model(inputs = inputs,outputs = outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_v2(input_shape,depth,num_class = 10):\n",
    "    \n",
    "    if (depth-2)%9 !=0:\n",
    "        raise ValueError('depth should be 9n+2 current Depth : '+depth)\n",
    "        \n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth-2)/9)\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = layer_RESNET(\n",
    "        inputs = inputs,\n",
    "        num_filters = num_filters_in,\n",
    "        conv_first = True\n",
    "    )\n",
    "    \n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides =1\n",
    "            \n",
    "            if stage ==0:\n",
    "                num_filters_out = num_filters_in*4\n",
    "                \n",
    "                if res_block == 0:\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filter_in*2\n",
    "                if res_block == 0:\n",
    "                    strides = 2\n",
    "                    \n",
    "            y= layer_RESNET(\n",
    "                inputs= x,\n",
    "                num_filter=num_filters_in,\n",
    "                kernel_size =1,\n",
    "                strides=strides,\n",
    "                activation= activation,\n",
    "                batch_normalization=batch_normalization,\n",
    "                conv_first=False\n",
    "            )\n",
    "            \n",
    "            y = layer_RESNET(\n",
    "                inputs=y,\n",
    "                num_filter=num_filter_in,\n",
    "                conv_first=False\n",
    "            )\n",
    "            \n",
    "            y = layer_RESNET(\n",
    "                inputs=y,\n",
    "                num_filter=num_filters_out,\n",
    "                conv_first=False\n",
    "            )\n",
    "            \n",
    "            if res_block == 0:\n",
    "                \n",
    "                x = layer_RESNET(\n",
    "                    inputs = x,\n",
    "                    num_filter=num_filters_out,\n",
    "                    kernel_size = 1,\n",
    "                    strides=strides,\n",
    "                    activation=None,\n",
    "                    batch_normalization=False\n",
    "                )\n",
    "            x =add([x,y])\n",
    "        num_filters_in =num_filters_out\n",
    "        \n",
    "        \n",
    "        \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size = 8)(x)\n",
    "    y = Flatten()(x)\n",
    "    \n",
    "    outputs = Dense(\n",
    "        num_classes,\n",
    "        activation = 'softmax',\n",
    "        kernel_initializer = 'he_normal'\n",
    "    )(y)\n",
    "    \n",
    "    model = Model(inputs = inputs,outputs = outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 32, 32, 16)   448         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 32, 32, 16)   64          conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 32, 32, 16)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 32, 32, 16)   2320        activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 32, 32, 16)   64          conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 32, 32, 16)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 32, 32, 16)   2320        activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 32, 32, 16)   64          conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 32, 32, 16)   0           activation_117[0][0]             \n",
      "                                                                 batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 32, 32, 16)   0           add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 32, 32, 16)   2320        activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 32, 32, 16)   64          conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 32, 32, 16)   0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 32, 32, 16)   2320        activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 32, 32, 16)   64          conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 32, 32, 16)   0           activation_119[0][0]             \n",
      "                                                                 batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 32, 32, 16)   0           add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 32, 32, 16)   2320        activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 32, 32, 16)   64          conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 32, 32, 16)   0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 32, 32, 16)   2320        activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 32, 32, 16)   64          conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 32, 32, 16)   0           activation_121[0][0]             \n",
      "                                                                 batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 32, 32, 16)   0           add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 16, 16, 32)   4640        activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 16, 16, 32)   128         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 16, 16, 32)   0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 16, 16, 32)   9248        activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 16, 16, 32)   544         activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 16, 16, 32)   128         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 16, 16, 32)   0           conv2d_138[0][0]                 \n",
      "                                                                 batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 16, 16, 32)   0           add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 16, 16, 32)   9248        activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 16, 16, 32)   128         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 16, 16, 32)   0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 16, 16, 32)   9248        activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 16, 16, 32)   128         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 16, 16, 32)   0           activation_125[0][0]             \n",
      "                                                                 batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 16, 16, 32)   0           add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 16, 16, 32)   9248        activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 16, 16, 32)   128         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 16, 16, 32)   0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 16, 16, 32)   9248        activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 16, 16, 32)   128         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 16, 16, 32)   0           activation_127[0][0]             \n",
      "                                                                 batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 16, 16, 32)   0           add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 8, 8, 64)     18496       activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 8, 8, 64)     256         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 8, 8, 64)     0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 8, 8, 64)     36928       activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 8, 8, 64)     2112        activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 8, 8, 64)     256         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 8, 8, 64)     0           conv2d_145[0][0]                 \n",
      "                                                                 batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 8, 8, 64)     0           add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 8, 8, 64)     36928       activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 8, 8, 64)     256         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 8, 8, 64)     0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 8, 8, 64)     36928       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 8, 8, 64)     256         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 8, 8, 64)     0           activation_131[0][0]             \n",
      "                                                                 batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 8, 8, 64)     0           add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 8, 8, 64)     36928       activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 8, 8, 64)     256         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 8, 8, 64)     0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 8, 8, 64)     36928       activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 8, 8, 64)     256         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 8, 8, 64)     0           activation_133[0][0]             \n",
      "                                                                 batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 8, 8, 64)     0           add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 64)     0           activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 64)           0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           650         flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(\n",
    "        input_shape=input_shape,\n",
    "        depth = depth\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    model = resnetv1(\n",
    "        input_shape = input_shape,\n",
    "        depth = depth\n",
    "    )\n",
    "    \n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = Adam(lr = lr_schedule(0)),\n",
    "    metrics = ['acc']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet20v1\n"
     ]
    }
   ],
   "source": [
    "print(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=os.path.join(os.getcwd(),'saved_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' %model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath = filepath,\n",
    "    monitor = 'val_acc',\n",
    "    verbose = 1,\n",
    "    save_best_only = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(\n",
    "    factor = np.sqrt(0.1),\n",
    "    cooldown = 0,\n",
    "    patience = 5,\n",
    "    min_lr = 0.5e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint,lr_reducer,lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.callbacks.ModelCheckpoint at 0x1c7d79f3490>,\n",
       " <tensorflow.python.keras.callbacks.ReduceLROnPlateau at 0x1c7d5f44640>,\n",
       " <tensorflow.python.keras.callbacks.LearningRateScheduler at 0x1c7d7898820>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "0.001\n",
      "1563/1563 [==============================] - 437s 278ms/step - loss: 1.8207 - acc: 0.4056 - val_loss: 1.6834 - val_acc: 0.5022\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.50220, saving model to C:\\Users\\KTDS\\Desktop\\im\\Resnet20\\saved_models\\cifar10_ResNet20v1_model.001.h5\n",
      "Epoch 2/200\n",
      "0.001\n",
      "1563/1563 [==============================] - 426s 273ms/step - loss: 1.2230 - acc: 0.6249 - val_loss: 1.2628 - val_acc: 0.6233\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.50220 to 0.62330, saving model to C:\\Users\\KTDS\\Desktop\\im\\Resnet20\\saved_models\\cifar10_ResNet20v1_model.002.h5\n",
      "Epoch 3/200\n",
      "0.001\n",
      "1335/1563 [========================>.....] - ETA: 1:00 - loss: 1.0405 - acc: 0.6933"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-440cacdcc1a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     model.fit(\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs = epochs,\n",
    "    validation_data=(x_test,y_test),\n",
    "    shuffle = True,\n",
    "    callbacks=callbacks)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False\n",
    "     )\n",
    "        \n",
    "    datagen.fit(x_train)\n",
    "    steps_per_epoch =  math.ceil(len(x_train) / batch_size)\n",
    "    model.fit(\n",
    "        x=datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "        verbose=1,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "scroes = model.evaluate(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    batch_size = batch_size,\n",
    "    verbose = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9501985311508179, 0.7296000123023987]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
