{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from config.ipynb\n",
      "importing Jupyter notebook from processingdata.ipynb\n",
      "importing Jupyter notebook from DeepFM.ipynb\n",
      "importing Jupyter notebook from FMlayer.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb # ipynb load 위한 모듈\n",
    "import config\n",
    "from processingdata import get_modified_data\n",
    "from DeepFM import DeepFM\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import perf_counter\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    file = pd.read_csv('data/adult_csv.csv', header=None)\n",
    "    file = file.dropna()\n",
    "    file = file.drop(file.index[0],axis = 0)\n",
    "    file = file.reset_index(drop = True)\n",
    "    X = file.loc[:, 0:13]\n",
    "    Y = file.loc[:, 14].map({'<=50K': 0, '>50K': 1})\n",
    "    \n",
    "    \n",
    "    X.columns = config.ALL_FIELDS\n",
    "    \n",
    "    field_dict, field_index, X_modified = \\\n",
    "        get_modified_data(X, config.ALL_FIELDS, config.CONT_FIELDS, config.CAT_FIELDS, False)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_modified, Y, test_size=0.2, stratify=Y)\n",
    "    \n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.cast(X_train.values, tf.float32), tf.cast(Y_train, tf.float32))) \\\n",
    "        .shuffle(30000).batch(config.BATCH_SIZE)\n",
    "\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.cast(X_test.values, tf.float32), tf.cast(Y_test, tf.float32))) \\\n",
    "        .shuffle(10000).batch(config.BATCH_SIZE)\n",
    "    return train_ds, test_ds, field_dict, field_index\n",
    "\n",
    "\n",
    "# Batch 단위 학습\n",
    "def train_on_batch(model, optimizer, acc, auc, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(inputs)\n",
    "        loss = tf.keras.losses.binary_crossentropy(from_logits=False, y_true=targets, y_pred=y_pred)\n",
    "\n",
    "    grads = tape.gradient(target=loss, sources=model.trainable_variables)\n",
    "\n",
    "    # apply_gradients()를 통해 processed gradients를 적용함\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # accuracy & auc\n",
    "    acc.update_state(targets, y_pred)\n",
    "    auc.update_state(targets, y_pred)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# 반복 학습 함수\n",
    "def train(epochs):\n",
    "    train_ds, test_ds, field_dict, field_index = get_data()\n",
    "    model = DeepFM(embedding_size=config.EMBEDDING_SIZE, num_feature=len(field_index),\n",
    "                   num_field=len(field_dict), field_index=field_index)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "    print(\"Start Training: Batch Size: {}, Embedding Size: {}\".format(config.BATCH_SIZE, config.EMBEDDING_SIZE))\n",
    "    start = perf_counter()\n",
    "    for i in range(epochs):\n",
    "        acc = BinaryAccuracy(threshold=0.8)\n",
    "        auc = AUC()\n",
    "        loss_history = []\n",
    "\n",
    "        for x, y in train_ds:\n",
    "            loss = train_on_batch(model, optimizer, acc, auc, x, y)\n",
    "            loss_history.append(loss)\n",
    "\n",
    "        print(\"Epoch {:03d}: 누적 Loss: {:.4f}, Acc: {:.4f}, AUC: {:.4f}\".format(\n",
    "            i, np.mean(loss_history), acc.result().numpy(), auc.result().numpy()))\n",
    "\n",
    "    test_acc = BinaryAccuracy(threshold=0.5)\n",
    "    test_auc = AUC()\n",
    "    for x, y in test_ds:\n",
    "        y_pred = model(x)\n",
    "        test_acc.update_state(y, y_pred)\n",
    "        test_auc.update_state(y, y_pred)\n",
    "\n",
    "    print(\"테스트 ACC: {:.4f}, AUC: {:.4f}\".format(test_acc.result().numpy(), test_auc.result().numpy()))\n",
    "    print(\"Batch Size: {}, Embedding Size: {}\".format(config.BATCH_SIZE, config.EMBEDDING_SIZE))\n",
    "    print(\"걸린 시간: {:.3f}\".format(perf_counter() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Prepared...\n",
      "X shape: (45222, 104)\n",
      "# of Feature: 104\n",
      "# of Field: 14\n",
      "Start Training: Batch Size: 256, Embedding Size: 5\n",
      "Epoch 000: 누적 Loss: 0.6175, Acc: 0.7509, AUC: 0.5305\n",
      "Epoch 001: 누적 Loss: 0.5287, Acc: 0.7520, AUC: 0.6720\n",
      "Epoch 002: 누적 Loss: 0.5131, Acc: 0.7520, AUC: 0.7119\n",
      "Epoch 003: 누적 Loss: 0.4982, Acc: 0.7524, AUC: 0.7442\n",
      "Epoch 004: 누적 Loss: 0.4845, Acc: 0.7516, AUC: 0.7722\n",
      "Epoch 005: 누적 Loss: 0.4697, Acc: 0.7520, AUC: 0.7941\n",
      "Epoch 006: 누적 Loss: 0.4560, Acc: 0.7523, AUC: 0.8093\n",
      "Epoch 007: 누적 Loss: 0.4440, Acc: 0.7526, AUC: 0.8204\n",
      "Epoch 008: 누적 Loss: 0.4333, Acc: 0.7527, AUC: 0.8289\n",
      "Epoch 009: 누적 Loss: 0.4246, Acc: 0.7523, AUC: 0.8350\n",
      "테스트 ACC: 0.8046, AUC: 0.8341\n",
      "Batch Size: 256, Embedding Size: 5\n",
      "걸린 시간: 19.291\n"
     ]
    }
   ],
   "source": [
    "train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
