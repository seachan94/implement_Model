{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from config.ipynb\n",
      "importing Jupyter notebook from processingdata.ipynb\n",
      "importing Jupyter notebook from DeepFM.ipynb\n",
      "importing Jupyter notebook from FMlayer.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb # ipynb load 위한 모듈\n",
    "import config\n",
    "from processingdata import get_modified_data\n",
    "from DeepFM import DeepFM\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import perf_counter\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    '''file = pd.read_csv('data/adult_csv.csv', header=None)\n",
    "    file = file.dropna()\n",
    "    file = file.drop(file.index[0],axis = 0)\n",
    "    file = file.reset_index(drop = True)\n",
    "    X = file.loc[:, 0:13]\n",
    "    Y = file.loc[:, 14].map({'<=50K': 0, '>50K': 1})'''\n",
    "    col = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\"]\n",
    "\n",
    "    da = [[1,2,3,\"q\",\"w\",\"e\",1],[4,5,6,\"r\",\"t\",\"y\",2],[7,8,9,\"u\",\"i\",\"o\",1],[1,2,3,\"q\",\"w\",\"e\",1]]\n",
    "\n",
    "    f = pd.DataFrame(da,columns=col)\n",
    "    X = f.drop('g')\n",
    "    Y = f[['g']]\n",
    "    \n",
    "    X.columns = config.ALL_FIELDS\n",
    "    \n",
    "    field_dict, field_index, X_modified = \\\n",
    "        get_modified_data(X, config.ALL_FIELDS, config.CONT_FIELDS, config.CAT_FIELDS, False)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_modified, Y, test_size=0.2, stratify=Y)  \n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(X_train.values, tf.float32), \n",
    "            tf.cast(Y_train, tf.float32)\n",
    "        )\n",
    "    ).shuffle(30000).batch(config.BATCH_SIZE)\n",
    "    \n",
    "    test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.cast(X_test.values, tf.float32), \n",
    "         tf.cast(Y_test, tf.float32))\n",
    "    ).shuffle(10000).batch(config.BATCH_SIZE)\n",
    "    \n",
    "    return train_ds, test_ds, field_dict, field_index\n",
    "\n",
    "\n",
    "# Batch 단위 학습\n",
    "def train_on_batch(model, optimizer, acc, auc, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(inputs)\n",
    "        loss = tf.keras.losses.binary_crossentropy(from_logits=False, y_true=targets, y_pred=y_pred)\n",
    "\n",
    "    grads = tape.gradient(target=loss, sources=model.trainable_variables)\n",
    "\n",
    "    # apply_gradients()를 통해 processed gradients를 적용함\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # accuracy & auc\n",
    "    acc.update_state(targets, y_pred)\n",
    "    auc.update_state(targets, y_pred)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# 반복 학습 함수\n",
    "def train(epochs):\n",
    "    train_ds, test_ds, field_dict, field_index = get_data()\n",
    "    model = DeepFM(embedding_size=config.EMBEDDING_SIZE, num_feature=len(field_index),\n",
    "                   num_field=len(field_dict), field_index=field_index)\n",
    "    \n",
    "   \n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "    print(\"Start Training: Batch Size: {}, Embedding Size: {}\".format(config.BATCH_SIZE, config.EMBEDDING_SIZE))\n",
    "    start = perf_counter()\n",
    "    for i in range(epochs):\n",
    "        acc = BinaryAccuracy(threshold=0.8)\n",
    "        auc = AUC()\n",
    "        loss_history = []\n",
    "\n",
    "        for x, y in train_ds:\n",
    "            loss = train_on_batch(model, optimizer, acc, auc, x, y)\n",
    "            loss_history.append(loss)\n",
    "            break\n",
    "\n",
    "        print(\"Epoch {:03d}: 누적 Loss: {:.4f}, Acc: {:.4f}, AUC: {:.4f}\".format(\n",
    "            i, np.mean(loss_history), acc.result().numpy(), auc.result().numpy()))\n",
    "\n",
    "    test_acc = BinaryAccuracy(threshold=0.5)\n",
    "    test_auc = AUC()\n",
    "    for x, y in test_ds:\n",
    "        y_pred = model(x)\n",
    "        test_acc.update_state(y, y_pred)\n",
    "        test_auc.update_state(y, y_pred)\n",
    "\n",
    "    print(\"테스트 ACC: {:.4f}, AUC: {:.4f}\".format(test_acc.result().numpy(), test_auc.result().numpy()))\n",
    "    print(\"Batch Size: {}, Embedding Size: {}\".format(config.BATCH_SIZE, config.EMBEDDING_SIZE))\n",
    "    print(\"걸린 시간: {:.3f}\".format(perf_counter() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
