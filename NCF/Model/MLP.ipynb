{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    \n",
    "    def __init__(self, user_num , item_num):\n",
    "        \n",
    "        user = Input(shape = (1,),dtype = 'int32')\n",
    "        user_embedding = Embedding(\n",
    "            user_num ,\n",
    "            32,\n",
    "            input_length = user.shape[1] \n",
    "        )(user)\n",
    "        user_embedding = Flatten()(user_embedding)\n",
    "        \n",
    "        \n",
    "        item = Input(shape = (1,) ,dtype = 'int32')\n",
    "        \n",
    "        item_embedding = Embedding(\n",
    "            item_num,\n",
    "            32,\n",
    "            input_length = item.shape[1]\n",
    "        )\n",
    "        item_embedding = Flatten()(item_embedding)\n",
    "        \n",
    "        concatenated = Concatenate()([user_embedding,item_embedding])\n",
    "        dropout = Dropout(rate = 0.2)(concatenated)\n",
    "        \n",
    "        #1 Layer\n",
    "        \n",
    "        layer_1 = Dense(units = 64, activation = 'relu',name = 'layer_1')(dropout)\n",
    "        dropout1 = Dropout(rate = 0.2, name = 'dropout1')(layer_1)\n",
    "        batch_norm1 = BatchNormalization(name ='batch_norm1')(dropout1)\n",
    "        \n",
    "        #2 Layer\n",
    "        \n",
    "        layer_2 = Dense(units = 32,activation = 'relu',name = 'layer_2')(batch_norm1)\n",
    "        droppout2 = Dropout(rate= 0.2,name = 'dropout2')(layer_2)\n",
    "        batch_norm2 = BatchNormalization(name = 'batchnorm_2')(droppout2)\n",
    "        \n",
    "        #3 Layer\n",
    "        \n",
    "        layer_3 = Dense(units = 16 , activation = 'relu',name = 'layer_3')(batch_norm2)\n",
    "        \n",
    "        #4 Layer\n",
    "        \n",
    "        layer_4 = Dense(units = 8 , activation = 'relu',name = 'layer_4')(layer_3)\n",
    "        \n",
    "        #Output\n",
    "        \n",
    "        output_layer = Dense(units = 1, \n",
    "                             kernel_initalizer = 'lecun_uniform',\n",
    "                             name = 'output')(layer_4)\n",
    "        \n",
    "        #model\n",
    "        self.model = Model([user,item],output_layer)\n",
    "        self.model.complie(\n",
    "            optimizer = 'adam',\n",
    "            loss = 'binary_crossentropy'\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def ModelMLP(self):\n",
    "        model = self.model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
