{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMF:\n",
    "    \n",
    "    def __init__(self, user_num,item_num):\n",
    "        \n",
    "        latent_features = 8\n",
    "        \n",
    "        user = Input(shape = (1,),dtype = 'int32')\n",
    "        item = Input(shape = (1,),dtype = 'int32')\n",
    "        \n",
    "        #embedding user, item for GMF \n",
    "        \n",
    "        gmf_user_embedding = Embedding(user_num, latent_features,input_length = user.shape[1])(user)\n",
    "        gmf_user_embedding = Flatten()(gmf_user_embedding)\n",
    "        \n",
    "        gmf_item_embedding = Embedding(item_num, latent_features, input_length = item.shape[1])(item)\n",
    "        gmf_item_embedding = Flatten()(gmf_item_embedding)\n",
    "        \n",
    "        #embedding user, item for MLP\n",
    "        \n",
    "        mlp_user_embedding = Embedding(user_num,32,input_length = user.shape[1])(user)\n",
    "        mlp_user_embedding = Flatten()(mlp_user_embedding)\n",
    "        \n",
    "        mlp_item_embedding = Embedding(item_num, 32, input_length = item.shape[1])(item)\n",
    "        mlp_item_embedding = Flatten()(mlp_item_embedding)\n",
    "        \n",
    "        #GMF layers\n",
    "        gmf_mul = Multiply()([gmf_user_embedding,gmf_item_embedding])\n",
    "        \n",
    "        #MLP layers\n",
    "        mlp_concat = Concatenate([mlp_user_embedding,mlp_item_embedding])\n",
    "        mlp_dropout = Dropout(0.2)(mlp_concat)\n",
    "        \n",
    "        #1 Layer \n",
    "        mlp_layer_1 = Dense(units = 64, activation = 'relu',name = 'mlp_layer1')(mlp_dropout)\n",
    "        mlp_dropout1 = Dropout(rate = 0.2 , name = 'mlp1d')(mlp_layer_1)\n",
    "        mlp_batchnorm1 = BatchNormalization()(mlp_dropout1)\n",
    "        \n",
    "        # 2 Layer\n",
    "        mlp_layer2 = Dense(units = 32, activation ='relu',name = 'mlp_layer2')(mlp_batchnorm1)\n",
    "        mlp_dropout2 = Dropout(rate = 0.2, name = 'mlp2d')(mlp_layer2)\n",
    "        mlp_batchnorm2 = BatchNormalization()(mlp_dropout2)\n",
    "        \n",
    "        # 3 layer\n",
    "        mlp_layer3  = Dense(units = 16,activation = 'relu',name = 'mlp_layer3')(mlp_batchnorm2)\n",
    "        \n",
    "        # 4 Layer\n",
    "        mlp_layer4 = Dense(units = 8 , activation = 'relu',name = 'mlp_layer4')(mlp_layer3)\n",
    "        \n",
    "        \n",
    "        # merget GMF + MLP\n",
    "        merge_vector = tf.keras.layers.concatenate([gmf_mul,mlp_layer4])\n",
    "        \n",
    "        outpur_layer = Dense(1, kernel_initalizer = 'lecun_uniform',name = 'output_layer')(merge_vector)\n",
    "        \n",
    "        self.model = Model([user,item],outpur_layer)\n",
    "        self.model.compile(\n",
    "            optimizer = 'adam',\n",
    "            loss = 'binary_crossentropy'\n",
    "        )\n",
    "        \n",
    "    def ModelDMF(self):\n",
    "        model = self.model\n",
    "        return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
